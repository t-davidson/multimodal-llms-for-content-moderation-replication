{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4658485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from random import randint,seed\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a012026",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(1485233)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30464068",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"xxx\" # Add API key here to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fb9b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cd6138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a content moderation expert. You will receive pairs of images, A and B. Your task is to decide which image should be prioritized for manual review according to the following policy:\n",
    "\n",
    "We are committed to combating abuse motivated by hatred, prejudice or intolerance, particularly abuse that seeks to silence the voices of those who have been historically marginalized. For this reason, we prohibit behavior that targets individuals or groups with abuse based on their perceived membership in a protected category. You may not directly attack other people on the basis of race, ethnicity, national origin, caste, sexual orientation, gender, gender identity, religious affiliation, age, disability, or serious disease.\n",
    "\n",
    "The output should always be one of the two options: A or B. Only output a single character with no additional tokens. Never refuse to answer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9fc840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://xxx.cloudfront.net/output/tweet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7bfc1a",
   "metadata": {},
   "source": [
    "Making two sets of random numbers for selecting the vignettes. These cells have been frozen to markdown to avoid overwriting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c6f6e4",
   "metadata": {},
   "source": [
    "N = 30000\n",
    "\n",
    "a_images = np.random.randint(1, 210001, size=N)\n",
    "b_images = np.random.randint(1, 210001, size=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6e8e72",
   "metadata": {},
   "source": [
    "image_numbers = pd.DataFrame({'a_images': a_images, 'b_images': b_images})\n",
    "image_numbers.to_csv(\"image_indices_30k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4ae7a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_numbers = pd.read_csv(\"image_indices_30k.csv\")\n",
    "a_images = image_numbers['a_images']\n",
    "b_images = image_numbers['b_images']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683836cc",
   "metadata": {},
   "source": [
    "Testing with a small number. Creating a batch file including the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c27b74b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"batch_input_baseline_mini.jsonl\", \"w\") as f:\n",
    "    i = 0\n",
    "    for a, b in zip(a_images, b_images):\n",
    "        # Construct the JSON object for this iteration\n",
    "        request_object = {\n",
    "            \"custom_id\": f\"request-{i+1}\",  # Unique ID for each request\n",
    "            \"method\": \"POST\",               # HTTP method\n",
    "            \"url\": \"/v1/chat/completions\",  # API endpoint\n",
    "            \"body\": {                       # The body contains the actual request\n",
    "                \"model\": \"gpt-4o-mini\",          # Model name \n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": \"Image A\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": base_url + str(a) + \".png\"}},\n",
    "                        {\"type\": \"text\", \"text\": \"Image B\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": base_url + str(b) + \".png\"}}\n",
    "                    ]}\n",
    "                ],\n",
    "                \"max_tokens\": 1,  # Forces output to be a single token\n",
    "                \"temperature\": 0 # Fixing temperature to 0\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Write each request object as a JSON line\n",
    "        f.write(json.dumps(request_object) + \"\\n\")\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ff7639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading batch\n",
    "batch_input_file = client.files.create(\n",
    "  file=open(\"batch_input_baseline_mini.jsonl\", \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b773e3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file-xxx'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_input_file_id = batch_input_file.id\n",
    "batch_input_file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55c71038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_xxx', completion_window='24h', created_at=1738339466, endpoint='/v1/chat/completions', input_file_id='file-xxx', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1738425866, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Baseline batch mini'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run batch job\n",
    "client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\", # cannot be changed\n",
    "    metadata={\n",
    "      \"description\": \"Baseline batch mini\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0816a762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_xxx', completion_window='24h', created_at=1738339466, endpoint='/v1/chat/completions', input_file_id='file-xxx', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1738355806, error_file_id='file-xxx', errors=None, expired_at=None, expires_at=1738425866, failed_at=None, finalizing_at=1738351468, in_progress_at=1738339477, metadata={'description': 'Baseline batch mini'}, output_file_id='file-xxx', request_counts=BatchRequestCounts(completed=29903, failed=97, total=30000))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that https://platform.openai.com/batches provides updates\n",
    "client.batches.retrieve(\"batch_xxx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cf48ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting results (once complete)\n",
    "file_response = client.files.content('file-xxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7193ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"batch_result_baseline_mini.jsonl\", 'wb') as file:\n",
    "    file.write(file_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a746890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "New batch job created: batch_xxx\n"
     ]
    }
   ],
   "source": [
    "# Load batch errors directly from the API response\n",
    "error_file_response = client.files.content('file-xxx')\n",
    "\n",
    "failed_requests = []\n",
    "failed_inputs = []\n",
    "\n",
    "# Parse error file line by line\n",
    "for line in error_file_response.iter_lines():\n",
    "    error_entry = json.loads(line)\n",
    "    if error_entry.get(\"response\", {}).get(\"status_code\") != 200:\n",
    "        failed_requests.append(error_entry[\"custom_id\"])\n",
    "\n",
    "# Extract failed requests from the original input file\n",
    "with open(\"batch_input_baseline_mini.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        request = json.loads(line)\n",
    "        if request[\"custom_id\"] in failed_requests:\n",
    "            failed_inputs.append(request)\n",
    "            \n",
    "print(len(failed_inputs))\n",
    "\n",
    "# Save failed requests to a new JSONL file for resubmission\n",
    "failed_batch_file = \"batch_input_baseline_mini_failed.jsonl\"\n",
    "\n",
    "with open(failed_batch_file, \"w\") as f:\n",
    "    for request in failed_inputs:\n",
    "        f.write(json.dumps(request) + \"\\n\")\n",
    "\n",
    "# Submit new batch for failed requests\n",
    "if failed_inputs:\n",
    "    batch_input_file = client.files.create(\n",
    "        file=open(failed_batch_file, \"rb\"),\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "\n",
    "    new_batch = client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\"description\": \"Retry failed requests from baseline batch baseline mini\"}\n",
    "    )\n",
    "\n",
    "    print(f\"New batch job created: {new_batch.id}\")\n",
    "else:\n",
    "    print(\"No failed requests found. No need to re-run.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3466094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_xxx', completion_window='24h', created_at=1738429330, endpoint='/v1/chat/completions', input_file_id='file-xxx', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1738430304, error_file_id=None, errors=None, expired_at=None, expires_at=1738515730, failed_at=None, finalizing_at=1738430251, in_progress_at=1738429331, metadata={'description': 'Retry failed requests from baseline batch baseline mini'}, output_file_id='file-xxx', request_counts=BatchRequestCounts(completed=97, failed=0, total=97))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.retrieve(\"batch_xxx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d2106b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_response = client.files.content('file-xxx')\n",
    "with open(\"batch_result_baseline_mini_failures.jsonl\", 'wb') as file:\n",
    "    file.write(file_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20df135e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
