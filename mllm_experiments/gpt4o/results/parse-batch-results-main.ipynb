{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2402b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f7d2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"batch_result_*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882e33b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [x for x in files if \"result\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b16614",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [x for x in files if \"alt\" not in x and \"single\" not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cc87b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705d8915",
   "metadata": {},
   "source": [
    "Each file has up to two versions. The `_failures` version consists of rows that were missed in the first batch. In all cases, missing rows were coded when these observations were passed in a second batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1de5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate through each file\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        # Read each line as a JSON object\n",
    "        for line in f:\n",
    "            record = json.loads(line)\n",
    "            # Add the filename as a new field\n",
    "            record['source_file'] = file\n",
    "\n",
    "            # Extract 'content' and 'refusal' from the 'choices' list if available\n",
    "            if 'response' in record and 'body' in record['response'] and 'choices' in record['response']['body']:\n",
    "                choices = record['response']['body']['choices']\n",
    "                if choices and isinstance(choices, list):\n",
    "                    # We assume there is at least one choice; you could add further checks here\n",
    "                    record['content'] = choices[0]['message'].get('content', None)\n",
    "                    record['refusal'] = choices[0]['message'].get('refusal', None)\n",
    "\n",
    "            # Append the record to the data list\n",
    "            data.append(record)\n",
    "\n",
    "# Create a pandas dataframe from the list of dictionaries\n",
    "df = pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d35f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(\n",
    "    model=lambda df: df[\"source_file\"].apply(lambda x: \"mini\" if \"mini\" in x else \"base\"),\n",
    "    prompt=lambda df: df[\"source_file\"].apply(lambda x: x.split(\"_\")[2] if len(x.split(\"_\")) > 2 else None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb772070",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"model\", \"prompt\"]).size().reset_index(name=\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d52363",
   "metadata": {},
   "source": [
    "Now merging in the image IDs that correspond to the request numbers. To do this, starting by creating a numeric ID vector, then using this to merge with `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5e8f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_numbers = pd.read_csv(\"../image_indices_30k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8290446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_numbers['custom_id'] = [f\"request-{i}\" for i in range(1, 30001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2294c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'Unnamed: 0' column\n",
    "image_numbers = image_numbers.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e994703",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_main = pd.merge(df_main, image_numbers, on='custom_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e597acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_ = merged_df[[\"source_file\", \"content\", \"model\", \"prompt\", \"response.body.usage.prompt_tokens\", \"a_images\", \"b_images\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc34bd36",
   "metadata": {},
   "source": [
    "Verifying that we have 30k rows for each combination of model and prompt and 29664 for the identical conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb22d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_.groupby([\"model\", \"prompt\"]).size().reset_index(name=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ef0a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_.to_csv(\"gpt4o-experiments-results-main.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
