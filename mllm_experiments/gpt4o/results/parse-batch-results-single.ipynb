{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2402b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8f7d2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"batch_result_*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "882e33b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [x for x in files if \"single\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20edce13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['batch_result_baseline_single_GPT4o_combined.jsonl',\n",
       " 'batch_result_baseline_single_GPT4o_mini_combined.jsonl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485f09b0",
   "metadata": {},
   "source": [
    "Ignoring first version using indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc1de5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate through each file\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        # Read each line as a JSON object\n",
    "        for line in f:\n",
    "            record = json.loads(line)\n",
    "            # Add the filename as a new field\n",
    "            record['source_file'] = file\n",
    "\n",
    "            # Extract 'content' and 'refusal' from the 'choices' list if available\n",
    "            if 'response' in record and 'body' in record['response'] and 'choices' in record['response']['body']:\n",
    "                choices = record['response']['body']['choices']\n",
    "                if choices and isinstance(choices, list):\n",
    "                    # We assume there is at least one choice; you could add further checks here\n",
    "                    record['content'] = choices[0]['message'].get('content', None)\n",
    "                    record['refusal'] = choices[0]['message'].get('refusal', None)\n",
    "\n",
    "            # Append the record to the data list\n",
    "            data.append(record)\n",
    "\n",
    "# Create a pandas dataframe from the list of dictionaries\n",
    "df = pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5502c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(\n",
    "    model=lambda df: df[\"source_file\"].apply(lambda x: \"mini\" if \"mini\" in x else \"base\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff65e4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d52363",
   "metadata": {},
   "source": [
    "Now merging in the image IDs that correspond to the request numbers. To do this, starting by creating a numeric ID vector, then using this to merge with `df`. Requests were coded numerically from one upwards.\n",
    "\n",
    "The \"single\" conjoint experiment has a different structure so needs to be merged differently to regular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b5e8f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_numbers = pd.read_csv(\"image_indices_30k.csv\")\n",
    "\n",
    "image_numbers_long = pd.DataFrame({\n",
    "    'image_number': pd.concat([image_numbers['a_images'], image_numbers['b_images']], ignore_index=True),\n",
    "    'custom_id': ['request-' + str(i) for i in range(1, 60001)]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8290446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(df, image_numbers_long, on='custom_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "143a5de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 26)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "764158bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>custom_id</th>\n",
       "      <th>error</th>\n",
       "      <th>source_file</th>\n",
       "      <th>content</th>\n",
       "      <th>refusal</th>\n",
       "      <th>response.status_code</th>\n",
       "      <th>response.request_id</th>\n",
       "      <th>response.body.id</th>\n",
       "      <th>response.body.object</th>\n",
       "      <th>...</th>\n",
       "      <th>response.body.usage.prompt_tokens_details.cached_tokens</th>\n",
       "      <th>response.body.usage.prompt_tokens_details.audio_tokens</th>\n",
       "      <th>response.body.usage.completion_tokens_details.reasoning_tokens</th>\n",
       "      <th>response.body.usage.completion_tokens_details.audio_tokens</th>\n",
       "      <th>response.body.usage.completion_tokens_details.accepted_prediction_tokens</th>\n",
       "      <th>response.body.usage.completion_tokens_details.rejected_prediction_tokens</th>\n",
       "      <th>response.body.service_tier</th>\n",
       "      <th>response.body.system_fingerprint</th>\n",
       "      <th>model</th>\n",
       "      <th>image_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batch_req_68291db65f108190a8003de6560e1dd9</td>\n",
       "      <td>request-1</td>\n",
       "      <td>None</td>\n",
       "      <td>batch_result_baseline_single_GPT4o_combined.jsonl</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>b46612a648eb013504e38bbab15a795a</td>\n",
       "      <td>chatcmpl-BYKDnzyJqqWNSjuouGGMHpWUZTOUC</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>default</td>\n",
       "      <td>fp_90122d973c</td>\n",
       "      <td>base</td>\n",
       "      <td>198641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>batch_req_68291db674e4819097b24cf152937b4b</td>\n",
       "      <td>request-2</td>\n",
       "      <td>None</td>\n",
       "      <td>batch_result_baseline_single_GPT4o_combined.jsonl</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>800702916039454f52c9763cd1a59015</td>\n",
       "      <td>chatcmpl-BYKCoN8NPX73ZmlQU3OGO9aZLgF0Y</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>default</td>\n",
       "      <td>fp_e5492b552a</td>\n",
       "      <td>base</td>\n",
       "      <td>97494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>batch_req_68291db681bc819084baf5abce00a7a0</td>\n",
       "      <td>request-3</td>\n",
       "      <td>None</td>\n",
       "      <td>batch_result_baseline_single_GPT4o_combined.jsonl</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>e3f26125e3fe9426623d3ba0e921dc67</td>\n",
       "      <td>chatcmpl-BYKCo2xTIGhhjvbUryc2VdD9rcZcQ</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>default</td>\n",
       "      <td>fp_e5492b552a</td>\n",
       "      <td>base</td>\n",
       "      <td>148936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>batch_req_68291db68e6c819082027cb4cf6c4b7f</td>\n",
       "      <td>request-4</td>\n",
       "      <td>None</td>\n",
       "      <td>batch_result_baseline_single_GPT4o_combined.jsonl</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>7e505e66787700e1ad26141ee1212aa4</td>\n",
       "      <td>chatcmpl-BYKCohuub7w3Y6xFE4IvvPbzufMLi</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>default</td>\n",
       "      <td>fp_b7faba9ef5</td>\n",
       "      <td>base</td>\n",
       "      <td>61789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>batch_req_68291db6a6a08190aba85c6ddf2947d5</td>\n",
       "      <td>request-5</td>\n",
       "      <td>None</td>\n",
       "      <td>batch_result_baseline_single_GPT4o_combined.jsonl</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>d140f704e681cac011a81c6d4f3c188a</td>\n",
       "      <td>chatcmpl-BYKCodRk62bJoI0AMNzZ5uKK7o0kQ</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>default</td>\n",
       "      <td>fp_e5492b552a</td>\n",
       "      <td>base</td>\n",
       "      <td>207911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           id  custom_id error  \\\n",
       "0  batch_req_68291db65f108190a8003de6560e1dd9  request-1  None   \n",
       "1  batch_req_68291db674e4819097b24cf152937b4b  request-2  None   \n",
       "2  batch_req_68291db681bc819084baf5abce00a7a0  request-3  None   \n",
       "3  batch_req_68291db68e6c819082027cb4cf6c4b7f  request-4  None   \n",
       "4  batch_req_68291db6a6a08190aba85c6ddf2947d5  request-5  None   \n",
       "\n",
       "                                         source_file content refusal  \\\n",
       "0  batch_result_baseline_single_GPT4o_combined.jsonl      No    None   \n",
       "1  batch_result_baseline_single_GPT4o_combined.jsonl     Yes    None   \n",
       "2  batch_result_baseline_single_GPT4o_combined.jsonl      No    None   \n",
       "3  batch_result_baseline_single_GPT4o_combined.jsonl     Yes    None   \n",
       "4  batch_result_baseline_single_GPT4o_combined.jsonl     Yes    None   \n",
       "\n",
       "   response.status_code               response.request_id  \\\n",
       "0                   200  b46612a648eb013504e38bbab15a795a   \n",
       "1                   200  800702916039454f52c9763cd1a59015   \n",
       "2                   200  e3f26125e3fe9426623d3ba0e921dc67   \n",
       "3                   200  7e505e66787700e1ad26141ee1212aa4   \n",
       "4                   200  d140f704e681cac011a81c6d4f3c188a   \n",
       "\n",
       "                         response.body.id response.body.object  ...  \\\n",
       "0  chatcmpl-BYKDnzyJqqWNSjuouGGMHpWUZTOUC      chat.completion  ...   \n",
       "1  chatcmpl-BYKCoN8NPX73ZmlQU3OGO9aZLgF0Y      chat.completion  ...   \n",
       "2  chatcmpl-BYKCo2xTIGhhjvbUryc2VdD9rcZcQ      chat.completion  ...   \n",
       "3  chatcmpl-BYKCohuub7w3Y6xFE4IvvPbzufMLi      chat.completion  ...   \n",
       "4  chatcmpl-BYKCodRk62bJoI0AMNzZ5uKK7o0kQ      chat.completion  ...   \n",
       "\n",
       "   response.body.usage.prompt_tokens_details.cached_tokens  \\\n",
       "0                                                  0         \n",
       "1                                                  0         \n",
       "2                                                  0         \n",
       "3                                                  0         \n",
       "4                                                  0         \n",
       "\n",
       "  response.body.usage.prompt_tokens_details.audio_tokens  \\\n",
       "0                                                  0       \n",
       "1                                                  0       \n",
       "2                                                  0       \n",
       "3                                                  0       \n",
       "4                                                  0       \n",
       "\n",
       "  response.body.usage.completion_tokens_details.reasoning_tokens  \\\n",
       "0                                                  0               \n",
       "1                                                  0               \n",
       "2                                                  0               \n",
       "3                                                  0               \n",
       "4                                                  0               \n",
       "\n",
       "   response.body.usage.completion_tokens_details.audio_tokens  \\\n",
       "0                                                  0            \n",
       "1                                                  0            \n",
       "2                                                  0            \n",
       "3                                                  0            \n",
       "4                                                  0            \n",
       "\n",
       "   response.body.usage.completion_tokens_details.accepted_prediction_tokens  \\\n",
       "0                                                  0                          \n",
       "1                                                  0                          \n",
       "2                                                  0                          \n",
       "3                                                  0                          \n",
       "4                                                  0                          \n",
       "\n",
       "   response.body.usage.completion_tokens_details.rejected_prediction_tokens  \\\n",
       "0                                                  0                          \n",
       "1                                                  0                          \n",
       "2                                                  0                          \n",
       "3                                                  0                          \n",
       "4                                                  0                          \n",
       "\n",
       "   response.body.service_tier  response.body.system_fingerprint  model  \\\n",
       "0                     default                     fp_90122d973c   base   \n",
       "1                     default                     fp_e5492b552a   base   \n",
       "2                     default                     fp_e5492b552a   base   \n",
       "3                     default                     fp_b7faba9ef5   base   \n",
       "4                     default                     fp_e5492b552a   base   \n",
       "\n",
       "   image_number  \n",
       "0        198641  \n",
       "1         97494  \n",
       "2        148936  \n",
       "3         61789  \n",
       "4        207911  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e597acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged[[\"source_file\", \"model\", \"content\", \"response.body.usage.prompt_tokens\", \"image_number\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90cea155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mini</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  count\n",
       "0  base  60000\n",
       "1  mini  60000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.groupby([\"model\"]).size().reset_index(name=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8a700e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv(\"gpt4o-experiments-results-single.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
