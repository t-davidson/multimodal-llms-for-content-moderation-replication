{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4658485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from random import randint,seed\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30464068",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"xxx\" # Add API key here to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fb9b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cd6138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a content moderation expert. You will receive pairs of images, A and B. Your task is to decide which image should be prioritized for manual review according to the following policy:\n",
    "\n",
    "We are committed to combating abuse motivated by hatred, prejudice or intolerance, particularly abuse that seeks to silence the voices of those who have been historically marginalized. For this reason, we prohibit behavior that targets individuals or groups with abuse based on their perceived membership in a protected category. You may not directly attack other people on the basis of race, ethnicity, national origin, caste, sexual orientation, gender, gender identity, religious affiliation, age, disability, or serious disease. \n",
    "\n",
    "Context is essential in content moderation decisions. Insults directed at dominant groups, such as white people, differ from expressions of hatred targeting minorities. Members of marginalized groups may also reclaim slurs, using them in ways that should not be classified as hate speech.\n",
    "\n",
    "The output should always be one of the two options: A or B. Only output a single character with no additional tokens. Never refuse to answer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9fc840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://xxx.cloudfront.net/output/tweet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7bfc1a",
   "metadata": {},
   "source": [
    "Reading in randomized images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb9154a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_numbers = pd.read_csv(\"image_indices_30k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90472c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_images = image_numbers['a_images']\n",
    "b_images = image_numbers['b_images']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683836cc",
   "metadata": {},
   "source": [
    "Testing with a small number. Creating a batch file including the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c27b74b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"batch_input_debiased.jsonl\", \"w\") as f:\n",
    "    i = 0\n",
    "    for a, b in zip(a_images, b_images):\n",
    "        # Construct the JSON object for this iteration\n",
    "        request_object = {\n",
    "            \"custom_id\": f\"request-{i+1}\",  # Unique ID for each request\n",
    "            \"method\": \"POST\",               # HTTP method\n",
    "            \"url\": \"/v1/chat/completions\",  # API endpoint\n",
    "            \"body\": {                       # The body contains the actual request\n",
    "                \"model\": \"gpt-4o\",          # Model name \n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": \"Image A\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": base_url + str(a) + \".png\"}},\n",
    "                        {\"type\": \"text\", \"text\": \"Image B\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": base_url + str(b) + \".png\"}}\n",
    "                    ]}\n",
    "                ],\n",
    "                \"max_tokens\": 1,  # Forces output to be a single token\n",
    "                \"temperature\": 0 # Fixing temperature to 0\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Write each request object as a JSON line\n",
    "        f.write(json.dumps(request_object) + \"\\n\")\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ff7639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading batch\n",
    "batch_input_file = client.files.create(\n",
    "  file=open(\"batch_input_debiased.jsonl\", \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b773e3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file-xxx'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_input_file_id = batch_input_file.id\n",
    "batch_input_file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55c71038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_xxx', completion_window='24h', created_at=1737736124, endpoint='/v1/chat/completions', input_file_id='file-xxx', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1737822524, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Debiasing 2025'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run batch job\n",
    "client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\", # cannot be changed\n",
    "    metadata={\n",
    "      \"description\": \"Debiasing 2025\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9f5b34",
   "metadata": {},
   "source": [
    "The `output_file_id` field will appear below once batches begin processing. This can be used to retrieve the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b52bc94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_xxx', completion_window='24h', created_at=1737736124, endpoint='/v1/chat/completions', input_file_id='file-xxx', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1737745920, error_file_id='file-xxx', errors=None, expired_at=None, expires_at=1737822524, failed_at=None, finalizing_at=1737742786, in_progress_at=1737736132, metadata={'description': 'Debiasing 2025'}, output_file_id='file-xxx', request_counts=BatchRequestCounts(completed=29918, failed=82, total=30000))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.retrieve(\"batch_xxx\") # Can also be viewed in OpenAI platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cf48ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting results (once complete)\n",
    "file_response = client.files.content('file-xxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7193ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"batch_result_debiased.jsonl\", 'wb') as file:\n",
    "    file.write(file_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5375aa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "New batch job created: batch_xxx\n"
     ]
    }
   ],
   "source": [
    "# Load batch errors directly from the API response\n",
    "error_file_response = client.files.content('file-xxx')\n",
    "\n",
    "failed_requests = []\n",
    "failed_inputs = []\n",
    "\n",
    "# Parse error file line by line\n",
    "for line in error_file_response.iter_lines():\n",
    "    error_entry = json.loads(line)\n",
    "    if error_entry.get(\"response\", {}).get(\"status_code\") != 200:\n",
    "        failed_requests.append(error_entry[\"custom_id\"])\n",
    "\n",
    "# Extract failed requests from the original input file\n",
    "with open(\"batch_input_debiased.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        request = json.loads(line)\n",
    "        if request[\"custom_id\"] in failed_requests:\n",
    "            failed_inputs.append(request)\n",
    "            \n",
    "print(len(failed_inputs))\n",
    "\n",
    "# Save failed requests to a new JSONL file for resubmission\n",
    "failed_batch_file = \"batch_input_debiased_failed.jsonl\"\n",
    "\n",
    "with open(failed_batch_file, \"w\") as f:\n",
    "    for request in failed_inputs:\n",
    "        f.write(json.dumps(request) + \"\\n\")\n",
    "\n",
    "# Submit new batch for failed requests\n",
    "if failed_inputs:\n",
    "    batch_input_file = client.files.create(\n",
    "        file=open(failed_batch_file, \"rb\"),\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "\n",
    "    new_batch = client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\"description\": \"Retry failed requests from debiasing batch 2025\"}\n",
    "    )\n",
    "\n",
    "    print(f\"New batch job created: {new_batch.id}\")\n",
    "else:\n",
    "    print(\"No failed requests found. No need to re-run.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51a4eecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_xxx', completion_window='24h', created_at=1738429554, endpoint='/v1/chat/completions', input_file_id='file-xxx', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1738430134, error_file_id=None, errors=None, expired_at=None, expires_at=1738515954, failed_at=None, finalizing_at=1738430127, in_progress_at=1738429555, metadata={'description': 'Retry failed requests from debiasing batch 2025'}, output_file_id='file-xxx', request_counts=BatchRequestCounts(completed=82, failed=0, total=82))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.retrieve(\"batch_xxx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e90d49ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_response = client.files.content('file-xxx')\n",
    "with open(\"batch_result_debiased_failures.jsonl\", 'wb') as file:\n",
    "    file.write(file_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed79fbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044bffa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
